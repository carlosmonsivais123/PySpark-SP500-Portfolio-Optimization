{"cells":[{"cell_type":"code","execution_count":8,"id":"5489415e","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType, TimestampType\n","\n","from pyspark.sql.functions import col,isnan, when, count"]},{"cell_type":"code","execution_count":2,"id":"e7e3fe41","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName(\"stock\").getOrCreate()\n","sc = spark.sparkContext\n","data_file = \"gs://stock-project-sp500/Data/S&P_500_Full_Stock_Data.csv\""]},{"cell_type":"code","execution_count":3,"id":"db435be5","metadata":{},"outputs":[],"source":["stock_schema = StructType([StructField('Symbol', StringType(), False),\n","                           StructField('Date', TimestampType(), False),\n","                           StructField('Open', FloatType(), True),\n","                           StructField('High', FloatType(), True),\n","                           StructField('Low', FloatType(), True),\n","                           StructField('Close', FloatType(), True),\n","                           StructField('Adj Close', FloatType(), True),\n","                           StructField('Volume', IntegerType(), True),\n","                           StructField('Description', StringType(), False),\n","                           StructField('Category2', StringType(), False),\n","                           StructField('Category3', StringType(), False),\n","                           StructField('GICS Sector', StringType(), False)])"]},{"cell_type":"code","execution_count":21,"id":"f8ae740c","metadata":{},"outputs":[],"source":["non_null_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"]},{"cell_type":"code","execution_count":4,"id":"572803f4","metadata":{},"outputs":[],"source":["stock_df = spark.read.csv(data_file,\n","                          header = True,\n","                          schema = stock_schema).cache()"]},{"cell_type":"code","execution_count":22,"id":"ffc47129","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+----+---+-----+---------+------+\n","|Open|High|Low|Close|Adj Close|Volume|\n","+----+----+---+-----+---------+------+\n","|   7|   7|  7|    7|        7|  9569|\n","+----+----+---+-----+---------+------+\n","\n"]}],"source":["from pyspark.sql.functions import isnan, when, count, col\n","stock_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in non_null_columns]).show()"]},{"cell_type":"code","execution_count":28,"id":"609567dc","metadata":{},"outputs":[{"data":{"text/plain":["['Symbol',\n"," 'Date',\n"," 'Open',\n"," 'High',\n"," 'Low',\n"," 'Close',\n"," 'Adj Close',\n"," 'Volume',\n"," 'Description',\n"," 'Category2',\n"," 'Category3',\n"," 'GICS Sector']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["stock_df.columns"]},{"cell_type":"code","execution_count":32,"id":"e3cc6f25","metadata":{},"outputs":[],"source":["from pyspark.sql import functions as F\n","columns = ['Symbol',\n"," 'Open',\n"," 'High',\n"," 'Low',\n"," 'Close',\n"," 'Adj Close',\n"," 'Volume']\n","# Ignoring groupBy column and considering cols which are required in aggregation\n","columns.remove(\"Symbol\")\n","agg_expression = [F.sum(when(stock_df[x].isNull(), 1).otherwise(0)).alias(x) for x in columns]\n","\n","null_values_by_stock = stock_df.groupby(\"Symbol\").agg(*agg_expression)"]},{"cell_type":"code","execution_count":38,"id":"2031a26d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+----+----+---+-----+---------+------+----+\n","|Symbol|Open|High|Low|Close|Adj Close|Volume|SUM1|\n","+------+----+----+---+-----+---------+------+----+\n","|  BF-B|   1|   1|  1|    1|        1|  1367|1372|\n","|    EA|   1|   1|  1|    1|        1|  1367|1372|\n","|  NLOK|   1|   1|  1|    1|        1|  1367|1372|\n","|   AEE|   1|   1|  1|    1|        1|  1367|1372|\n","|   HPQ|   1|   1|  1|    1|        1|  1367|1372|\n","|   PVH|   1|   1|  1|    1|        1|  1367|1372|\n","|    CI|   1|   1|  1|    1|        1|  1367|1372|\n","|   AAP|   0|   0|  0|    0|        0|     0|   0|\n","|   AIZ|   0|   0|  0|    0|        0|     0|   0|\n","|   AME|   0|   0|  0|    0|        0|     0|   0|\n","|   AES|   0|   0|  0|    0|        0|     0|   0|\n","|   BDX|   0|   0|  0|    0|        0|     0|   0|\n","|  ABBV|   0|   0|  0|    0|        0|     0|   0|\n","|   CSX|   0|   0|  0|    0|        0|     0|   0|\n","|  ALGN|   0|   0|  0|    0|        0|     0|   0|\n","|    CL|   0|   0|  0|    0|        0|     0|   0|\n","|   ADM|   0|   0|  0|    0|        0|     0|   0|\n","|   AMT|   0|   0|  0|    0|        0|     0|   0|\n","|    DD|   0|   0|  0|    0|        0|     0|   0|\n","|   AVB|   0|   0|  0|    0|        0|     0|   0|\n","+------+----+----+---+-----+---------+------+----+\n","only showing top 20 rows\n","\n"]}],"source":["df2 = null_values_by_stock.withColumn(\n","    'SUM1',\n","    sum([F.col(c) for c in columns])\n",")\n","df2.orderBy(col('SUM1').desc()).show(20)"]},{"cell_type":"code","execution_count":36,"id":"790afde3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+----+----+---+-----+---------+------+----+\n","|Symbol|Open|High|Low|Close|Adj Close|Volume|SUM1|\n","+------+----+----+---+-----+---------+------+----+\n","|  ABMD|   0|   0|  0|    0|        0|     0|   0|\n","|   AVY|   0|   0|  0|    0|        0|     0|   0|\n","|   CRL|   0|   0|  0|    0|        0|     0|   0|\n","|   AXP|   0|   0|  0|    0|        0|     0|   0|\n","|   CDW|   0|   0|  0|    0|        0|     0|   0|\n","+------+----+----+---+-----+---------+------+----+\n","only showing top 5 rows\n","\n"]}],"source":["df2.show(5)"]},{"cell_type":"code","execution_count":null,"id":"d50b31fc","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}