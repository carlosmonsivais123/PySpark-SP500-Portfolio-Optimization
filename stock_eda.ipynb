{"cells":[{"cell_type":"markdown","id":"36d41e01","metadata":{},"source":["# Stock EDA and Data Clean Up"]},{"cell_type":"markdown","id":"4ee8b573","metadata":{},"source":["### Libraries"]},{"cell_type":"code","execution_count":1,"id":"0c95fe16","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession, functions as F\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType,\\\n","FloatType, TimestampType\n","from pyspark.sql.functions import isnan, when, count, col"]},{"cell_type":"markdown","id":"f0469094","metadata":{},"source":["### Spark Session"]},{"cell_type":"code","execution_count":2,"id":"e7e3fe41","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName(\"stock\").getOrCreate()\n","sc = spark.sparkContext\n","data_file = \"gs://stock-project-sp500/Data/S&P_500_Full_Stock_Data.csv\""]},{"cell_type":"markdown","id":"310cb99a","metadata":{},"source":["### Data Schema"]},{"cell_type":"code","execution_count":3,"id":"69561e97","metadata":{},"outputs":[],"source":["stock_schema = StructType([StructField('Symbol', StringType(), False),\n","                           StructField('Date', TimestampType(), False),\n","                           StructField('Open', FloatType(), True),\n","                           StructField('High', FloatType(), True),\n","                           StructField('Low', FloatType(), True),\n","                           StructField('Close', FloatType(), True),\n","                           StructField('Adj Close', FloatType(), True),\n","                           StructField('Volume', IntegerType(), True),\n","                           StructField('Description', StringType(), False),\n","                           StructField('Category2', StringType(), False),\n","                           StructField('Category3', StringType(), False),\n","                           StructField('GICS Sector', StringType(), False)])"]},{"cell_type":"markdown","id":"46522e6f","metadata":{},"source":["### Reading the Data"]},{"cell_type":"code","execution_count":4,"id":"8712ca1f","metadata":{},"outputs":[],"source":["stock_df = spark.read.csv(data_file,\n","                          header = True,\n","                          schema = stock_schema).cache()"]},{"cell_type":"markdown","id":"b296cca5","metadata":{},"source":["### Null and Missing Values"]},{"cell_type":"code","execution_count":5,"id":"b1fb501a","metadata":{},"outputs":[],"source":["# Only looking at these columns because the schema defined the other columns as not nullable.\n","null_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"]},{"cell_type":"code","execution_count":6,"id":"16018fa1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 0:=============================>                             (2 + 2) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["+----+----+---+-----+---------+------+\n","|Open|High|Low|Close|Adj Close|Volume|\n","+----+----+---+-----+---------+------+\n","|   7|   7|  7|    7|        7|  9569|\n","+----+----+---+-----+---------+------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Number of Null values per column\n","stock_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in null_columns]).show()"]},{"cell_type":"code","execution_count":7,"id":"94e82623","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------+----+----+---+-----+---------+------+------------------+\n","|Symbol|Open|High|Low|Close|Adj Close|Volume|Missing Values Sum|\n","+------+----+----+---+-----+---------+------+------------------+\n","|    EA|   1|   1|  1|    1|        1|  1367|              1372|\n","|    CI|   1|   1|  1|    1|        1|  1367|              1372|\n","|   PVH|   1|   1|  1|    1|        1|  1367|              1372|\n","|  NLOK|   1|   1|  1|    1|        1|  1367|              1372|\n","|  BF-B|   1|   1|  1|    1|        1|  1367|              1372|\n","|   HPQ|   1|   1|  1|    1|        1|  1367|              1372|\n","|   AEE|   1|   1|  1|    1|        1|  1367|              1372|\n","+------+----+----+---+-----+---------+------+------------------+\n","\n"]}],"source":["# Creating dataframe with the null values\n","agg_expression = [F.sum(when(stock_df[x].isNull(), 1).otherwise(0)).alias(x) for x in null_columns]\n","null_values_by_stock = stock_df.groupby(\"Symbol\").agg(*agg_expression)\n","\n","null_values_by_stock = null_values_by_stock.withColumn('Missing Values Sum', sum([F.col(c) for c in null_columns]))\n","null_values_by_stock.filter(null_values_by_stock[\"Missing Values Sum\"] > 0).show()"]},{"cell_type":"code","execution_count":19,"id":"c337eba8","metadata":{},"outputs":[],"source":["stock_df_missing_values = stock_df.filter(col(\"Open\").isNull()|col(\"High\").isNull()\\\n","                                         |col(\"Low\").isNull()|col(\"Close\").isNull()\\\n","                                         |col(\"Adj Close\").isNull()|col(\"Volume\").isNull())"]},{"cell_type":"code","execution_count":20,"id":"485147f7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 9569 rows with missing values.\n"]}],"source":["print(\"There are {} rows with missing values.\".format(stock_df_missing_values.count()))"]},{"cell_type":"markdown","id":"af7a4776","metadata":{},"source":["### Dropping Rows with Null Values"]},{"cell_type":"code","execution_count":null,"id":"fab12855","metadata":{},"outputs":[],"source":["stock_df = stock_df.dropna(how = 'any')\n","stock_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in null_columns]).show()"]},{"cell_type":"markdown","id":"20394290","metadata":{},"source":["### Features"]},{"cell_type":"markdown","id":"63cd332c","metadata":{},"source":["#### Date Feautures: Day of Week, Month, Year"]},{"cell_type":"code","execution_count":null,"id":"5a1e3aeb","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"bc62d82b","metadata":{},"source":["#### Lag 1, Lag2, Lag3, Lag4, Lag 5"]},{"cell_type":"code","execution_count":null,"id":"79b2b43e","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}